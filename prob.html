<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Probability and Statistics</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Probability and Statistics</h1>
				</section>
				<section>
					<h2>Random Experiment</h2>
					<p>An experiment for which we cannot predict the outcome in advance.
					</br>
					Example: Coin Tossing
					</p>
				</section>
				<section>
					<h2>Are they really unpredictable?</h2>
					<p style="text-align: justify;">
						In some cases, no! For instance, if we know the exact position of the coin at the moment that it is being flipped, and also we are aware of all the forces having an impact on this procedure, we can exactly predict what is going to happen.
					</br>
					However, we usually have much less knowledge about the experiment and we would like to model the experiment using all we have.
					</p>
				</section>
				<section>
					<h2>Are they really unpredictable?</h2>
					<p>
						In some cases, yes! Quantum mechanical processes are an example of this. Read More: <a href="shorturl.at/auJPZ">shorturl.at/auJPZ</a>
			
					</br>
					Remember, we are trying to model the experiment using "ALL WE HAVE"!
					</p>
				</section>
				<section>
					<h2>Sample Space</h2>
					The set of all possible outcomes for an experiment</br>
					Example: When you toss a coin, the sample space is 
					\[
					\Omega=S=\{\mathrm{Head, Tail}\} \]
				</section>
				<section>
					Another example: When rolling a dice, we have 
					\[
					S = \{1,2,3,4,5,6\}
					\]
				
				In this case, we can consider "the outcome being an odd number" an "event".
				</section>
				<section>
					<h2>Event</h2>
					An event is a subset of the sample space.
				</br>
				Example: "the outcome being an odd number" is equivalent to having \[E=\{1,3,5\}\]
				
				Obviously we have \[E\subseteq S\]
				</section>
				<section>
					<h2>
						Probability Function
					</h2>
					A function $P:A\mapsto [0,1]$
					where $A$ is an event. The following properties should hold for $P$:<br><br>
					<ul>
						<li>
							$\forall A\subset\Omega \quad 0\le P(A)\le 1$
						</li>
						<li>
							$P(\Omega)=1$
						</li>
						<li>
							If $A$ and $B$ are disjoint ($A \cap B=\emptyset$), then we have: $P(A \cup B)=P(A)+P(B)$
						</li>
						</ul>
				</section>
				<section>
					<h2>Some properties of the probability function</h2>
						$$P(A^C)=1 - P(A) $$
						Proof: 

						$$(\Omega = A \cup A^C) \land (A \cap A^C = \emptyset)$$ $$\implies 1 = P(\Omega) = P(A \cup A^C) = P(A) + P(A^C)$$
						$$\implies 1 = P(A)+P(A^C)$$
				</section>
				<section>
					<h2>Some properties of the probability function</h2>
					$$P(A \cup B) = P(A)+P(B)-P(A \cap B)$$
					Proof: 
					$$ (i): P(A \cup (B \cap A^C)) = P(A) + P(B \cap A^C)$$
					$$ \implies P(A \cup B) = P(A) + P(B \cap A^C) $$
				</section>
				<section>
					<h2>Some properties of the probability function</h2>
					$$P(A \cup B) = P(A)+P(B)-P(A \cap B)$$
					Proof: 
					$$ (ii): P((B \cap A) \cup (B \cap A^C)) = P(B \cap A) + P(B \cap A^C) $$
					$$ \implies P(B \cap A^C) = P(B) - P(A \cap B) $$
				</section>
				<section>
					<h2>Conditional Probability</h2>
					$$P(A|B) := \dfrac{P(A \cap B)}{P(B)}$$
					Note: This is only defined if $P(B)>0$.
				</section>
				<section>
					<h2>Is it really a probability function?</h2>
				</section>
				<section>
					$$ 0 \le P(A \cup B) \le 1 \newline P(B) >0 \newline \implies P(A|B) \in [0,1]$$
				</section>
				<section>
					$$ \Omega = B \implies P(\Omega|B) = P(B|B) = \dfrac{P(B \cap B)}{P(B)} = 1$$
				</section>
				<section>
					$$ A_1 \cap A_2 = \emptyset \implies P(A_1 \cup A_2 | B) = \dfrac{P((A_1 \cup A_2)\cap B)}{P(B)} \newline = \dfrac{P((A_1 \cap B) \cup (A_2 \cap B))}{P(B)} = \dfrac{P(A_1 \cap B)+P(A_2 \cap B)}{P(B)} \newline \dfrac{P(A_1 \cap B)}{P(B)} + \dfrac{P(A_2 \cap B)}{P(B)} \newline = P(A_1 | B) + P(A_2 | B)$$
				</section>
				<section>
					<h2>Bayes Theorem</h2>
					$$P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}$$
					Proof:
					$$ P(A|B) = \dfrac{P(A \cap B)}{P(B)} \implies P(A|B)P(B) = P(A \cap B) \newline P(B|A) = \dfrac{P(B \cap A)}{P(A)} \implies P(B|A)P(A) = P(A \cap B)$$
				</section>
				<section>
					<h2>Partition of a set</h2>
					A family of sets $P$ is a partition of $S$ if and only if all of the following conditions hold:
					<br><br>
					<ol>
						<li>$\emptyset \notin P$</li>
						<li>$\cup_{X\in P} X = S$</li>
						<li>$\forall A,B \in P \quad A\cap B = \emptyset$</li>
					</ol>
				</section>
				<section>
					<h2>The Law of Total Probability</h2>
					Assume that $\Omega$ is partitioned into $B_i$'s. Then we have:<br>
					$$ P(A) = \sum_i P(A\cap B_i) = \sum_i P(A|B_i)P(B_i)$$
					Proof:<br>
					$$
					A = A \cap \Omega \implies P(A) = P(A\cap \Omega) \stackrel{\text{$ \Omega = \cup_i B_i $}}{\implies}
					\newline P(A) = P(A\cap (\cup_i B_i)) = P(\cup_i (A\cap B_i)) \stackrel{\text{$ \forall i,j (A\cap B_i)\cap (A\cap B_j) = \emptyset $}}{=}
					\newline \sum_i P(A\cap B_i) = \sum_i P(A|B_i) P(B_i)
					$$
				</section>
				<section>
					<h2>Independent events</h2>
					Two events $A$ and $B$ are called independent if one of these hold:<br><br>
					<ul>
						<li>$P(B|A) = P(B)$ and $P(A|B)=P(A)$ </li>
						<li>$P(A)=0$ or $P(B)=0$</li>
					</ul>
				</section>
				<section>
					<h2>Independent Events</h2>
					$$
					P(A|B) = P(A) \land P(B|A) = P(B)
					\newline
					\implies P(A\cap B) = P(A|B)P(B) = P(A)P(B)
					\newline \implies P(A \cap B) = P(A)P(B)
					$$
				</section>
				<section>
					<h2>Independent Events given another Event</h2>
					$$ P(A|B,C) = P(A|C) \land P(B|A,C) = P(B|C) 
					$$
				</section>
				<section>
					<h2>Independent Events given another Event</h2>
					$$  
					P(A|B,C) = P(A|C) \iff \frac{P(A\cap B \cap C)}{P(B\cap C)} = 
					\frac{P(A\cap C)}{P(C)}
					\newline \iff
					\frac{P(A\cap B \cap C)}{P(A\cap C)} = \frac{P(B\cap C)}{P(C)} 
					\newline \iff
					P(B|A,C) = P(B|C)
					$$
				</section>
				<section>
					<h2>Chain Rule</h2>
					$$
					P(A_1 \cup A_2 \cup \dots \cup A_k)
					=
					P(\cup_{i=1}^k) = \newline
					\sum_{i=1}^k P(A_i) - \sum_{i,j} P(A_i \cap A_j)
					+ \sum_{i,j,k} P(A_i \cap A_j \cap A_k) - \dots
					$$
				</section>
				<section>
					<h2>Chain Rule</h2>
					$$
					P(A_1 \cap A_2 \cap \dots \cap A_k)
					= \newline
					P(A_1)P(A_2 | A_1)P(A_3| A_2, A_1)
					P(A_4 | A_3,A_2,A_1) \dots \newline
					P(A_k|A_{k-1}, A_{k-2}, \dots, A_1)
					$$
				</section>
				<section>
					<h2>Random Variable</h2>
					A function $X:\Omega\to\mathbb{R}$ which takes an outcome of a random experiment as its input, <br>and outputs a real number.
					<br><br>
					Example: $$ X(\mathrm{Heads}) = 0 \newline X(\mathrm{Tails}) = 1$$
				</section>
				<section>
					<h2>Discrete vs. Continuous</h2>
					If the range of the R.V. is countable, it's called discrete.<br>
					If it is uncountably infinite, (usually an interval), it's continuous.
				</section>
				<section>
					<h2>Discrete Random Variable</h2>
					Experiment: Rolling a dice
					<br>
					For each face $f$, define $X(f)=f+1$
				</section>
				<section>
					<h2>Continuous Random Variable</h2>
					Experiment: Exploring the Status of the Weather
					<br> Random Variable: The Temperature
					<br>
					<br>Note: A random variable actually simplifies the complicated situation of the outcome of an experiment such as the position of the molecules present in the air, the status of the sun, etc. 
				</section>
				<section>
					<h2>Probability Mass Function (PMF)</h2>
					Assume that $R_X$ is the range of an R.V. like $X$.<br>
					A function $p_X:R_X\to [0,1]$ for which the following conditions hold:
					<br><br><ul>
						<li>$\forall x \quad p_X(x)\ge 0$</li>
						<li>$\sum_{x \in \Omega_X} p_X(x) = 1$</li>
					</ul>
				</section>
				<section>
					<h2>Probability Mass Function (PMF)</h2>
					$$
					X(\mathrm{Heads}) = 0 \quad \land \quad X(\mathrm{Tails}) = 1 \implies R_X = \{0,1\}
					\newline
					p(0) = \frac{1}{2} \newline
					p(1) = \frac{1}{2}
					$$
				</section>
				<section>
					<h2>Probability Mass Function vs. Probability Function</h2>
					PMF: $\quad p:\Omega \to [0,1]$<br>
					Probability Function: $\quad \mathbb{P}:F \to [0,1]$
				</section>
				<section>
					<h2>Probability Mass Function vs. Probability Function</h2>
					PMF: $\quad p:\mathrm{outcome} \mapsto r\in [0,1]$<br>
					Probability Function: $\quad \mathbb{P}:\mathrm{event} \mapsto r\in [0,1]$
				</section>
				<section>
					<h2>Cumulative Distribution Function (CDF)</h2>
					$$
					\forall x \in R_X \quad F_X(x) = \mathbb{P}(\{\omega\in \Omega:X(\omega) \le x\}) = \mathbb{P}(X \le x)
					$$
				</section>
				<section>
					<h2>CDF is Non-decreasing</h2>
					<ul>
						<li>
							$\lim_{x\to-\infty} F(x)=0$
							<br>
							Since: $F(-\infty)=\mathbb{P}(X \le -\infty)=0$
						</li><br>
						<li>
							$\lim_{x\to+\infty} F(x)=1$
							<br>
							Since: $F(+\infty)=\mathbb{P}(X \le +\infty)=1$
						</li><br>
						<li>
							$x_1 \le x_2 \implies F(x_1) \le F(x_2)$
						</li>
					</ul>
				</section>
				<section>
					<h2>Question</h2>
					Assume 1,000,000 people, each paying 10,000 dollars are participating in a game.
					<br>At the end, only one person will win, and the reward will be 100,000,000 dollars. Is it wise to participate?
				</section>
				<section>
					<h2>Probability Approach</h2>
					Experiment: Measuring the change in our money after participating in the game.
					<br>
					Outcome: The amount of change
					<br>
					Random Variable: The amount of change <br>$X(i)=i \quad \forall i$
				</section>
				<section>
					We have two cases: 1. Winning 2. Losing
					<br>
					$$
					\mathbb{P}(\mathrm{Winning}) = \frac{1}{1,000,000}
					$$
					If we win, the change will be:<br>
					-10,000 + 100,000,000 = 99990000
				</section>
				<section>
					We have two cases: 1. Winning ~100M 2. Losing 10K
					<br>
					$$
					\mathbb{P}(\mathrm{Losing}) = \frac{1}{999999}
					$$
					If we win, the change will be:<br>
					-10,000
				</section>
				<section>
					We calculate a weighted average of the outcome in these two cases.
					<br>
					The weight of each case is the probability of it.
					<br>
					$$
					\sum_{x \in R_X} x\mathbb{P}(x) = \newline 99990000\times \frac{1}{1000000} + (-10000)\times \frac{999999}{1000000}
					\newline = -9900
					$$
					So, on average, we will lose!
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
		<script src="plugin/math/math.js"></script>
		<script>
		  Reveal.initialize({
			math: {
			  mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
			  config: 'TeX-AMS_HTML-full',
			  // pass other options into `MathJax.Hub.Config()`
			  TeX: { Macros: { RR: "{\\bf R}" } }
			},
			plugins: [ RevealMath ]
		  });
		  Reveal.initialize({ slideNumber: 'c/t' });

		</script>
	</body>
</html>
